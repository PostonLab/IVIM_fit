bids_dir: '/mnt/poston/EvaETP_IVIM/bids_data/bids'
output_dir: '/mnt/poston/EvaETP_IVIM/results'

#enable printing debug statements during parsing -- disable if generating dag visualization
debug: False

derivatives: False #will search in bids/derivatives if True; can also be path(s) to derivatives datasets

#list of analysis levels in the bids app
analysis_levels: &analysis_levels
 - participant


#mapping from analysis_level to set of target rules or files
targets_by_analysis_level:
  participant:
    - ''  # if '', then the first rule is run

#this configures the pybids grabber - create an entry for each type of input you want to grab
# indexed by name of input
#   dictionary for each input is passed directly to pybids get()
#    https://bids-standard.github.io/pybids/generated/bids.layout.BIDSLayout.html#bids.layout.BIDSLayout.get

pybids_inputs:
  dwi:
    filters:
      suffix: "dwi"
      extension: ".nii.gz"
      invalid_filters: "allow"
      datatype: "dwi"
    wildcards:
      - subject
      - acquisition
      - run
      - direction

  T1w:
    filters:
      suffix: "T1w"
      extension: ".nii.gz"
      datatype: "anat"
      #desc: "brain" # Require a skull-stripped brain
      #part: ["mag", false]
    wildcards:
      - subject
      #- run



#configuration for the command-line parameters to make available
# passed on the argparse add_argument()
parse_args:

#---  core BIDS-app options --- (do not modify below)

  bids_dir:
    help: The directory with the input dataset formatted according
          to the BIDS standard.

  output_dir:
    help: The directory where the output files
          should be stored. If you are running group level analysis
          this folder should be prepopulated with the results of the
          participant level analysis.

  analysis_level:
    help: Level of the analysis that will be performed.
    choices: *analysis_levels

  --participant-label:
    help: The label(s) of the participant(s) that should be analyzed. The label
          corresponds to sub-<participant_label> from the BIDS spec
          (so it does not include "sub-"). If this parameter is not
          provided all subjects should be analyzed. Multiple
          participants can be specified with a space separated list.
    nargs: '+'

  --exclude-participant-label:
    help: The label(s) of the participant(s) that should be excluded. The label
          corresponds to sub-<participant_label> from the BIDS spec
          (so it does not include "sub-"). If this parameter is not
          provided all subjects should be analyzed. Multiple
          participants can be specified with a space separated list.
    nargs: '+'

  --derivatives:
    help: 'Path(s) to a derivatives dataset, for folder(s) that contains multiple derivatives datasets (default: %(default)s) '
    default: False
    nargs: '+'


 # custom command-line parameters can then be added, these will get added to the config and also accessible to plugins
 # below are examples for plugin and custom parameters (e.g. config['smoothing_fwhm'])
  --skip-bids-validation:
    help: 'Skip validation of BIDS dataset. BIDS validation is performed by
          default using the bids-validator plugin (if installed/enabled) or with the pybids
          validator implementation (if bids-validator is not installed/enabled).'
    dest: "plugins.validator.skip"
    action: "store_true"
    default: False



#--- workflow specific configuration -- below is just an example:


  # B0 masking options
  --masking_method:
    help: 'Brain masking method to use for b0 (default: %(default)s)'
    nargs: '?'
    choices: 
      - 'b0_BET'
      - 'b0_SyN'
      - 'b0_synthstrip'
    default: 'b0_synthstrip'

  --b0_bet_frac:
    help: 'BET fractional intensity threshold for b0 masking 
          (default: %(default)s)'
    default: 0.5

  # SDC Options
  --gradcorrect_coeffs:
    help: 'Path to file containing scanner specific gradient correction 
          coefficients. Use this to enable gradient non-linearity correction. 
          (default: %(default)s)'
    default: null
    # default: '/project/ctb-akhanf/akhanf/opt/grad/.coeff_AC84.grad'

  --sdc_method:
    help: 'Set the susceptibility distortion correction (SDC) method to be used. 
          By default, the optimal correction method is chosen based on the data 
          available ("topup" if 2+ phase encoding directions or "synthsr" if 
          single phase encoding direction). To skip SDC, set method to "none". 
          (default: %(default)s)'
    default: 'optimal'
    choices:
      - 'optimal'
      - 'topup'
      - 'sdcflow'
      - 'synthsr'
      - 'synb0'
      - 'none'

  --sdc_method_alternate:
    help: 'Set alternate method to be used for single phase encoding SDC when 
          "--sdc_method" is set to "optimal", otherwise this flag is ignored.
          (default: %(default)s)'
    default: 'synthsr'
    choices:
      - 'sdcflow'
      - 'synthsr'
      - 'synb0'
          
  # Eddy options
  --use_eddy_s2v:
    help: 'Enable slice-to-volume correction in Eddy. Your dwi json must either 
          include SliceTiming information, or you must specify it with the 
          --slspec-txt flag. If any subjects do not have this information, 
          they will be run without slice-to-volume enabled. You must also use 
          the --use_eddy_gpu option. (default: %(default)s)'
    action: 'store_true'
    default: False

  --use_eddy_gpu:
    help: 'Use GPU-based version of eddy (must set container path in config)'
    action: 'store_true'
    default: False

  --skip_eddy_quad:
    help: 'Disables eddy_quad QC report (default: %(default)s)'
    action: 'store_true'
    dest: 'eddy_no_quad'
    default: False

  # Metadata options
  --slspec_txt:
    help: 'Path to custom slspec txt file for use with eddy. Must use this if 
          SliceTiming does not exist in the JSON (default: %(default)s)'
    default: False
    type: Path

  --default_phase_encoding_direction:
    help: 'Sets the PhaseEncodingDirection to use for dwi acquisitions where it 
          is not specified in the JSON file. By default, none will be assumed, 
          and the workflow will fail for subjects where this JSON tag is 
          missing (default: %(default)s)'
    default: ''
    choices:
      - 'i'
      - 'i-'
      - 'j'
      - 'j-'
      - 'k'
      - 'k-'
  --gradcorrect_skip_t1w:
    action: 'store_true'
    default: False


  # Bedpost options:
  --use_bedpost: 
    help: 'Enable bedpost (disabled by default)'
    action: 'store_false'
    dest: 'no_bedpost'
    default: True

  --use_bedpost_gpu:
    help: 'Use GPU-based version of bedpost (must set container path in config)'
    action: 'store_true'
    default: False

  # Registration options
  --rigid_dwi_t1_init:
    help: 'Type of initialization to use for dwi to t1 rigid registration. 
          (default: %(default)s)'
    nargs: '?'
    choices: 
      - 'identity'
      - 'image-centers'
    default: 'identity'

  --rigid_dwi_t1_iters:
    help: 'Number of iterations to use at each multi-resolution stage for dwi 
          to t1 rigid registration. (default: %(default)s)'
    default: '50x50'

  # Workflow options
  --fs_license:
    help: 'Path to the Freesurfer license file (needed for synb0 SDC method)'
    type: Path
    default: False 

  # Workflow metadata
  --version:
    help: 'Print the version of snakedwi'
    action: version
    version: "0.2.0"


#singularity containers
singularity:
  synthstrip: 'docker://freesurfer/synthstrip:1.3'
  itksnap: 'docker://khanlab/itksnap:latest' 
  ants: 'docker://kaczmarj/ants:2.3.4'
  mrtrix: 'docker://mrtrix3/mrtrix3:3.0.3'
  python: 'docker://khanlab/pythondeps-snakedwi:v0.2.0'
  prepdwi: 'docker://khanlab/prepdwi:latest' 
  fsl: 'docker://fnndsc/fsl:6.0.4-cuda9.1'
  synthsr: 'docker://akhanf/synthsr:main'


default_effective_echo_spacing: 0.0001 #if not defined in JSON files

template: MNI152NLin2009cSym

#Eddy flags
eddy:
  flags:
    verbose: True
    repol: True
    cnr_maps: True
    residuals: True
    data_is_shelled: True
  with_s2v:
    mporder: 6
    s2v_niter: 5
    s2v_lambda: 1
    s2v_interp: trilinear
    ol_type: 'both'  #can be sw, gw, or both (use sw if no multi-band)
  without_s2v:
    ol_type: 'sw'  #can be sw, gw, or both (use sw if no multi-band)


# Options for resampling dwi in T1w space
#  1. can resample as T1w resolution
#  2. can resample as original dwi resolution 
#  3. can resample as specified resolution
resample_dwi:
  resample_scheme: 'orig' # should be one of: ['T1w', 'orig', 'custom']
  custom_resolution: #only needed if the 'custom' 
  resample_mm: 
    - 1.0
    - 1.0
    - 1.0

execution:
  slurm:
    sbatch_exec: /usr/bin/sbatch
    sbatch_args: "-p general -n 8 -t 4:00:00"